{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armis Data Hack Challenge - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "DEVICES_PATH = \"all_devices.csv\"\n",
    "CHUNK_PATH = \"chunk-\" # + '1','2',...,'23' + '.csv'\n",
    "submission = pd.DataFrame(columns=[\"network_id\", \"device_id\", \"confidence\"])\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1 = pd.read_csv(CHUNK_PATH + '1' + '.csv',index_col=[0]) #index_col=[0] to use 1st col as index\n",
    "cols = chunk1.columns\n",
    "chunk1 = chunk1.groupby(['network_id','device_id']).aggregate({'host': 'nunique','packets_count': 'sum',\n",
    "                                                           'inbound_bytes_count': 'sum','outbound_bytes_count': 'sum',\n",
    "                                                           'port_dst' : 'nunique',  'service_device_id' : 'nunique',\n",
    "                                                           'packets_count' : 'sum','packet_loss' : 'sum',\n",
    "                                                           'retransmit_count': 'sum', 'latency' : 'sum','session_count' : 'sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1['in_out_ratio'] = chunk1.inbound_bytes_count / chunk1.packets_count\n",
    "chunk1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = chunk1.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk1.drop(['inbound_bytes_count', 'outbound_bytes_count'], axis=1, inplace=True) #drop linear correlated features\n",
    "\n",
    "corr = chunk1.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "chunk1.reset_index(level=[0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the simple min-max normalization in order to normalize the confidence values to 0-1 range.\n",
    "# Higher score means that this device is probably more anomalous.\n",
    "def calc_normalized_decision(decision_function_result):\n",
    "    decision_function_result = -1 * decision_function_result\n",
    "    minimum = decision_function_result.min()\n",
    "    maximum = decision_function_result.max()\n",
    "    return (decision_function_result - minimum) / (maximum - minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features\n",
    "- replacing 'inbound_bytes_count', 'outbound_bytes_count' which are highly correlated with 'packet_counts' with 'in_out_ratio'\n",
    "- this feature can tell if device is sending the requests only for attack proposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df_in):\n",
    "    df = df_in.copy()\n",
    "    df = df.groupby(['network_id','device_id']).aggregate({'host': 'nunique','packets_count': 'sum',\n",
    "                                                           'inbound_bytes_count': 'sum','outbound_bytes_count': 'sum',\n",
    "                                                           'port_dst' : 'nunique',  'service_device_id' : 'nunique',\n",
    "                                                           'packets_count' : 'sum','packet_loss' : 'sum',\n",
    "                                                           'retransmit_count': 'sum', 'latency' : 'sum','session_count' : 'sum'})\n",
    "    df['in_out_ratio'] = df.inbound_bytes_count / df.outbound_bytes_count\n",
    "    df.drop(['inbound_bytes_count', 'outbound_bytes_count'], axis=1, inplace=True) #drop linear correlated features\n",
    "    return df\n",
    "\n",
    "def detect_anomaly(df,esitmator):\n",
    "    df_out = df.copy()\n",
    "    esitmator.fit(df_out.values)\n",
    "    decision_function_result = esitmator.decision_function(df_out.values)\n",
    "    df_out[\"confidence\"] = calc_normalized_decision(decision_function_result)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating over chunks:\n",
    "iso = IsolationForest(behaviour='new',random_state=rng,max_samples=0.25,contamination=0.15,n_estimators=250,n_jobs=-1)\n",
    "cols= pd.read_csv('chunk-1.csv',chunksize = 2,index_col=[0]).get_chunk(2).columns\n",
    "\n",
    "for i in range (1,23):\n",
    "    chunk_path = CHUNK_PATH + str(i) + '.csv'\n",
    "    if i == 1:\n",
    "       mini_chunk_iso = pd.read_csv(chunk_path,index_col=[0])\n",
    "    else:\n",
    "        mini_chunk_iso = pd.read_csv(chunk_path,index_col=[0],names=cols,header=None) #index_col=[0] to use 1st col as index, names= we have the header only in the 1st file\n",
    "        #print(\"chunk-\"+ str(i) + str(mini_chunk.network_id.iloc[0])) which net_id related to chunk\n",
    "        #print(len(mini_chunk.device_id.unique().tolist())) how many unique devices in each mini_chunk\n",
    "        \n",
    "    mini_chunk_iso = extract_features(mini_chunk_iso)\n",
    "    mini_chunk_iso = detect_anomaly(mini_chunk_iso,iso)\n",
    "    mini_chunk_iso.drop(['in_out_ratio','host','packets_count','port_dst','service_device_id','packets_count',\n",
    "                     'packet_loss','retransmit_count', 'latency','session_count'],axis='columns',inplace=True)\n",
    "    mini_chunk_iso = mini_chunk_iso.groupby(['network_id','device_id']).aggregate({\"confidence\": \"mean\"})\n",
    "    mini_chunk_iso.reset_index(level=[0,1], inplace=True)\n",
    "    submission = submission.append(mini_chunk_iso)\n",
    "    submission = submission.groupby(['network_id','device_id']).aggregate({\"confidence\": \"mean\"})\n",
    "    submission.reset_index(level=[0,1], inplace=True)\n",
    "    total = len(submission.index)\n",
    "    print(\"at chunk-\" + str(i)+ f' {total:,}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(submission.device_id.unique())\n",
    "print(submission.info())\n",
    "print(submission.describe())\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_to_submit = submission.to_json(orient='values')\n",
    "\n",
    "from urllib import request\n",
    "import json\n",
    "\n",
    "leaderboard_name = \"armis\"\n",
    "host = \"leaderboard.datahack.org.il\"\n",
    "\n",
    "# Name of the user\n",
    "submitter = \"Data Sniffers\"\n",
    "\n",
    "predictions = json.loads(arr_to_submit)\n",
    "\n",
    "jsonStr = json.dumps({'submitter': submitter, 'predictions': predictions})\n",
    "data = jsonStr.encode('utf-8')\n",
    "req = request.Request(f\"https://{host}/{leaderboard_name}/api/\",\n",
    "                      headers={'Content-Type': 'application/json'},\n",
    "                      data=data)\n",
    "resp = request.urlopen(req)\n",
    "print(json.load(resp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
